<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Fire Scene Size-up Voice Recorder</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 2em;
      background: #f6f9fc;
    }
    #controls {
      margin-bottom: 1em;
    }
    #status {
      margin-top: 0.5em;
      font-weight: bold;
      color: #1976d2;
    }
    #transcript {
      margin-top: 1.5em;
      background: #fff;
      padding: 1em;
      border-radius: 6px;
      box-shadow: 0 2px 6px #0001;
      min-height: 2em;
    }
    button {
      padding: 0.8em 1.4em;
      font-size: 1.1em;
      border: none;
      border-radius: 6px;
      background: #1976d2;
      color: #fff;
      cursor: pointer;
      margin-right: 1em;
      transition: background 0.2s;
    }
    button:active {
      background: #105295;
    }
    #stopBtn {
      background: #c62828;
    }
    #stopBtn:active {
      background: #8b1a1a;
    }
    #transcriptTitle {
      margin-bottom: 0.3em;
      font-weight: bold;
      color: #444;
    }
  </style>
</head>
<body>
  <h1>Fire Scene Size-Up Voice Recorder</h1>
  <div id="controls">
    <button id="recordBtn">ðŸŽ¤ Start Recording</button>
    <button id="stopBtn" disabled>Stop</button>
    <span id="status"></span>
  </div>
  <div id="transcriptTitle" style="display:none;">Transcript:</div>
  <div id="transcript"></div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let mimeTypeUsed = "audio/webm";
    let extUsed = "webm";

    function getSupportedMimeType() {
      // Prefer mp4/m4a on Apple devices
      const isApple = /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent) && !window.MSStream;
      const types = isApple
        ? ['audio/mp4', 'audio/m4a', 'audio/webm;codecs=opus', 'audio/webm']
        : ['audio/webm;codecs=opus', 'audio/webm', 'audio/mp4', 'audio/m4a'];
      for (const type of types) {
        if (MediaRecorder.isTypeSupported(type)) return type;
      }
      return '';
    }

    function getExtensionForMimeType(mime) {
      if (mime.includes('mp4')) return 'mp4';
      if (mime.includes('m4a')) return 'm4a';
      if (mime.includes('mp3')) return 'mp3';
      if (mime.includes('wav')) return 'wav';
      return 'webm';
    }

    const recordBtn = document.getElementById("recordBtn");
    const stopBtn = document.getElementById("stopBtn");
    const statusSpan = document.getElementById("status");
    const transcriptDiv = document.getElementById("transcript");
    const transcriptTitle = document.getElementById("transcriptTitle");

    recordBtn.onclick = async () => {
      // Request permission and start recording
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        let mimeType = getSupportedMimeType();
        if (!mimeType) mimeType = '';

        mediaRecorder = mimeType
          ? new MediaRecorder(stream, { mimeType })
          : new MediaRecorder(stream);

        mimeTypeUsed = mediaRecorder.mimeType || "audio/webm";
        extUsed = getExtensionForMimeType(mimeTypeUsed);

        audioChunks = [];
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) audioChunks.push(event.data);
        };

        mediaRecorder.onstart = () => {
          statusSpan.textContent = "Recording... Speak your scene size-up.";
          recordBtn.disabled = true;
          stopBtn.disabled = false;
          transcriptTitle.style.display = "none";
          transcriptDiv.textContent = "";
        };

        mediaRecorder.onstop = async () => {
          statusSpan.textContent = "Processing audio...";
          recordBtn.disabled = false;
          stopBtn.disabled = true;

          const audioBlob = new Blob(audioChunks, { type: mimeTypeUsed });
          console.log("Blob type:", audioBlob.type, "Name:", `audio.${extUsed}`);
          const formData = new FormData();
          formData.append("audio", audioBlob, `audio.${extUsed}`);

          // Upload to your Netlify function endpoint
          try {
            const res = await fetch("/.netlify/functions/transcribe", {
              method: "POST",
              body: formData
            });
            const data = await res.json();
            if (data.transcript) {
              transcriptTitle.style.display = "block";
              transcriptDiv.textContent = data.transcript;
              statusSpan.textContent = "Transcription complete.";
            } else if (data.error) {
              transcriptTitle.style.display = "none";
              transcriptDiv.textContent = "";
              statusSpan.textContent = "Transcription failed: " + data.error;
            } else {
              transcriptTitle.style.display = "none";
              transcriptDiv.textContent = "";
              statusSpan.textContent = "Unknown error during transcription.";
            }
          } catch (err) {
            transcriptTitle.style.display = "none";
            transcriptDiv.textContent = "";
            statusSpan.textContent = "Network error: " + err.message;
          }
        };

        mediaRecorder.start();
      } catch (err) {
        statusSpan.textContent = "Mic error: " + (err.message || err);
        recordBtn.disabled = false;
        stopBtn.disabled = true;
      }
    };

    stopBtn.onclick = () => {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
        statusSpan.textContent = "Recording stopped. Transcribing...";
      }
    };
  </script>
</body>
</html>
